## Description

Детектор интентов. Каждый utterance приходит разбитый на предложения с помощью sentseg, каждое предложение
эмбеддится с помощью Universal sentence encoder (USE, https://arxiv.org/pdf/1803.11175.pdf).
В файле `src/detector.py` лежат различные детекторы.

## Описание детекторов:

- **USESimpleDetector**:  каждое предложение utterance сравнивается по метрике (*cosine similarity*) с предложениями интентов, берется максимум скора по всем предложениям и отсекается по трешхолду, вычисленному заранее.
- **USERegCombinedDetector**: каждое предложение сначала прогоняется через regexp, если же ни один интент не замэтчился - отправляем предложение в **USESimpleDetector**.
- **ClassifierDetector**: (линейный) классификатор, обученный поверх эмбеддингов USE.
- **ClassRegCombinedDetector** (TBD): то же самое что и **USERegCombinedDetector**, только c **ClassifierDetector**.

## TODO:

- Code refactoring
- train_model.py

## Метрики

**USERegCombinedDetector**:

| metrics/intents | exit        | repeat      | what\_is\_your\_name | where\_are\_you\_from | what\_can\_you\_do | who\_made\_you | what\_is\_your\_job |
|-----------------|-------------|-------------|----------------------|-----------------------|--------------------|----------------|---------------------|
| precision       | 0.933369776 | 0.819418869 | 0.996363636          | 0.958124098           | 0.851321586        | 0.876727199    | 0.92990404          |
| recall          | 0.617079005 | 0.731826007 | 0.818103175          | 0.87984127            | 0.72               | 0.877472177    | 0.905040404         |
| f1              | 0.735439153 | 0.767964591 | 0.893786162          | 0.909311858           | 0.670418219        | 0.874162102    | 0.912530126         |

**Linear classifier**

| metrics/intents | doing\_well         | dont\_understand    | exit                | no                  | opinion\_request    | repeat              | tell\_me\_more      | what\_can\_you\_do  | what\_is\_your\_job | what\_is\_your\_name | what\_time           | where\_are\_you\_from | who\_made\_you      | yes                 |
|-----------------|---------------------|---------------------|---------------------|---------------------|---------------------|---------------------|---------------------|---------------------|---------------------|----------------------|----------------------|-----------------------|---------------------|---------------------|
| precision       | 1.0                | 0.9976132744067527 | 0.997037155800165  | 0.9928205128205129 | 0.9999851249504165 | 1.0                | 1.0                | 0.945025975582778  | 0.9843170520003156 | 1.0                 | 0.7928571428571429  | 1.0                  | 0.9931632667466793 | 0.996165137614679  |
| recall          | 0.8401911659358271 | 0.8826411889019138 | 0.9534053182283264 | 0.5802337593382821 | 0.9958364712926503 | 0.950080000441964  | 0.5446212121212122 | 0.6972514166507493 | 0.7562545787545786 | 0.8627738927738926  | 0.215               | 0.9214330995708471   | 0.9666612339229802 | 0.5717203116196646 |
| f1              | 0.9120129891799224 | 0.9358415110352029 | 0.9746897449315843 | 0.7194057170314414 | 0.9979061770597972 | 0.9742250386801233 | 0.6900003591180062 | 0.7985519789654074 | 0.8506173289454824 | 0.9243565391639006  | 0.32399999999999995 | 0.9588085002450688   | 0.979446891092533  | 0.7238899498265154 |




## Getting started

В папке src/data должен быть tokenizer_english.pickle - токенайзер из NLTK.

Чтобы добавить интент, нужно:
 1. Вписать в `<intent_data_path>/intent_phrases.json` имя вашего интента, фразы/регекспы фраз, по которым будет идти матчинг, допустимые в этом случае знаки пунктуации, а также min_precision - минимально приемлимый precision для подбора трешхолда.
 2. Затем выполнить `python3 create_data.py <intent_data_path>/intent_phrases.json -p`, чтобы добавить эмбеддинги фраз, сами фразы (`-p` key) трешхолды и параметры для вычисления *confidence* (`-t` key). Они будут лежать в `<intent_data_path>/intent_data.json`
 3. Чтобы обучить **ClassifierDetector** на новых фразах (новых интентах). выполнить `python3 train_model.py --data_path <intent_data_path>/intent_data.json`.

Пример запуска внутри докера:
 ```
  python3 create_data.py /data/classifier_data/intent_phrases.json -p
  python /data/classifier_data/train_model.py --data_path /data/classifier_data/intent_data.json --model_path /data/classifier_data/models/linear_classifier.h5
``
