## Description

Детектор интентов. Каждый utterance приходит разбитый на предложения с помощью sentseg, каждое предложение
эмбеддится с помощью Universal sentence encoder (USE, https://arxiv.org/pdf/1803.11175.pdf).
В файле `src/detector.py` лежат различные детекторы.

## Описание детекторов:

- **USESimpleDetector**:  каждое предложение utterance сравнивается по метрике (*cosine similarity*) с предложениями интентов, берется максимум скора по всем предложениям и отсекается по трешхолду, вычисленному заранее.
- **USERegCombinedDetector**: каждое предложение сначала прогоняется через regexp, если же ни один интент не замэтчился - отправляем предложение в **USESimpleDetector**.
- **ClassifierDetector**: (линейный) классификатор, обученный поверх эмбеддингов USE.
- **ClassRegCombinedDetector** (TBD): то же самое что и **USERegCombinedDetector**, только c **ClassifierDetector**.

## TODO:

- Code refactoring
- train_model.py

## Метрики

**USERegCombinedDetector**:

| metrics/intents | exit        | repeat      | what\_is\_your\_name | where\_are\_you\_from | what\_can\_you\_do | who\_made\_you | what\_is\_your\_job |
|-----------------|-------------|-------------|----------------------|-----------------------|--------------------|----------------|---------------------|
| precision       | 0.933369776 | 0.819418869 | 0.996363636          | 0.958124098           | 0.851321586        | 0.876727199    | 0.92990404          |
| recall          | 0.617079005 | 0.731826007 | 0.818103175          | 0.87984127            | 0.72               | 0.877472177    | 0.905040404         |
| f1              | 0.735439153 | 0.767964591 | 0.893786162          | 0.909311858           | 0.670418219        | 0.874162102    | 0.912530126         |

**Linear classifier**

| metrics/intents | doing\_well         | exit                | no                  | opinion\_request    | repeat              | what\_can\_you\_do  | what\_is\_your\_job | what\_is\_your\_name | what\_time           | where\_are\_you\_from | who\_made\_you      | yes                 |
|-----------------|---------------------|---------------------|---------------------|---------------------|---------------------|---------------------|---------------------|----------------------|----------------------|-----------------------|---------------------|---------------------|
| precision       | 1.0                | 0.9976492501586588 | 0.98989898989899   | 1.0                | 1.0                | 0.9466849463359761 | 0.9899153439153439 | 1.0                 | 0.7                 | 1.0                  | 0.9948945746252829 | 0.992916574349276  |
| recall          | 0.7601139666226485 | 0.9047476855441822 | 0.5829890437556341 | 0.9961322473553231 | 0.9588686239499966 | 0.6470110822724839 | 0.7501034259857791 | 0.8644376456876458  | 0.17666666666666667 | 0.9301677535963364   | 0.9707656793829503 | 0.6093325907349282 |
| f1              | 0.8604726481199705 | 0.9488519977121372 | 0.7261145145308341 | 0.9980620828373148 | 0.9789416745965344 | 0.7610891012021961 | 0.8493925495587538 | 0.924069046117484   | 0.2720238095238095  | 0.9635960241449988   | 0.9824870350886613 | 0.7531116010096562 |



## Getting started

В папке src/data должен быть tokenizer_english.pickle - токенайзер из NLTK.

Чтобы добавить интент, нужно:
 1. Вписать в `<intent_data_path>/intent_phrases.json` имя вашего интента, фразы/регекспы фраз, по которым будет идти матчинг, допустимые в этом случае знаки пунктуации, а также min_precision - минимально приемлимый precision для подбора трешхолда.
 2. Затем выполнить `python3 create_data.py <intent_data_path>/intent_phrases.json -p`, чтобы добавить эмбеддинги фраз, сами фразы (`-p` key) трешхолды и параметры для вычисления *confidence* (`-t` key). Они будут лежать в `<intent_data_path>/intent_data.json`
 3. Чтобы обучить **ClassifierDetector** на новых фразах (новых интентах). выполнить `python3 train_model.py --data_path <intent_data_path>/intent_data.json`.

Пример запуска внутри докера:
 ```
  python3 create_data.py /data/classifier_data/intent_phrases.json -p
  python /data/classifier_data/train_model.py --data_path /data/classifier_data/intent_data.json --model_path /data/classifier_data/models/linear_classifier.h5
``
