## Description

Детектор интентов. Каждый utterance приходит разбитый на предложения с помощью sentseg, каждое предложение
эмбеддится с помощью Universal sentence encoder (USE, https://arxiv.org/pdf/1803.11175.pdf).
В файле `src/detector.py` лежат различные детекторы.

## Описание детекторов:

- **USESimpleDetector**:  каждое предложение utterance сравнивается по метрике (*cosine similarity*) с предложениями интентов, берется максимум скора по всем предложениям и отсекается по трешхолду, вычисленному заранее.
- **USERegCombinedDetector**: каждое предложение сначала прогоняется через regexp, если же ни один интент не замэтчился - отправляем предложение в **USESimpleDetector**.
- **ClassifierDetector**: (линейный) классификатор, обученный поверх эмбеддингов USE.
- **ClassRegCombinedDetector** (TBD): то же самое что и **USERegCombinedDetector**, только c **ClassifierDetector**.

## TODO:

- Code refactoring
- train_model.py

## Метрики

**USERegCombinedDetector**:

| metrics/intents | exit        | repeat      | what\_is\_your\_name | where\_are\_you\_from | what\_can\_you\_do | who\_made\_you | what\_is\_your\_job |
|-----------------|-------------|-------------|----------------------|-----------------------|--------------------|----------------|---------------------|
| precision       | 0.933369776 | 0.819418869 | 0.996363636          | 0.958124098           | 0.851321586        | 0.876727199    | 0.92990404          |
| recall          | 0.617079005 | 0.731826007 | 0.818103175          | 0.87984127            | 0.72               | 0.877472177    | 0.905040404         |
| f1              | 0.735439153 | 0.767964591 | 0.893786162          | 0.909311858           | 0.670418219        | 0.874162102    | 0.912530126         |

**Linear classifier**

| metrics/intents | doing\_well         | exit                | no                  | opinion\_request    | repeat              | what\_can\_you\_do  | what\_is\_your\_job | what\_is\_your\_name | what\_time          | where\_are\_you\_from | who\_made\_you      | yes                 |
|-----------------|---------------------|---------------------|---------------------|---------------------|---------------------|---------------------|---------------------|----------------------|---------------------|-----------------------|---------------------|---------------------|
| precision       | 1.0                | 0.9957566015457537 | 0.996875           | 0.9999702587477154 | 1.0                | 0.9503100015926103 | 0.9840973084886129 | 1.0                 | 0.8428571428571429 | 1.0                  | 0.9873981921707122 | 0.9994318181818181 |
| recall          | 0.7531955028193906 | 0.89743873758975   | 0.591587770674458  | 0.9959258867978426 | 0.9601906952406472 | 0.7289806481575114 | 0.7309752747252747 | 0.8711868686868687  | 0.2269047619047619 | 0.9283421310605322   | 0.9739471946825546 | 0.5764626771168314 |
| f1              | 0.8561397410596598 | 0.9438709330439414 | 0.7321526545017534 | 0.9979438287228376 | 0.9796066994256455 | 0.8228695864343385 | 0.8372190437168847 | 0.9300065005638727  | 0.3466269841269841 | 0.9626550465737825   | 0.9803364876563535 | 0.7290860217494429 |


## Getting started

В папке src/data должен быть tokenizer_english.pickle - токенайзер из NLTK.

Чтобы добавить интент, нужно:
 1. Вписать в `<intent_data_path>/intent_phrases.json` имя вашего интента, фразы/регекспы фраз, по которым будет идти матчинг, допустимые в этом случае знаки пунктуации, а также min_precision - минимально приемлимый precision для подбора трешхолда.
 2. Затем выполнить `python3 create_data.py <intent_data_path>/intent_phrases.json -p`, чтобы добавить эмбеддинги фраз, сами фразы (`-p` key) трешхолды и параметры для вычисления *confidence* (`-t` key). Они будут лежать в `<intent_data_path>/intent_data.json`
 3. Чтобы обучить **ClassifierDetector** на новых фразах (новых интентах). выполнить `python3 train_model.py --data_path <intent_data_path>/intent_data.json`.

Пример запуска внутри докера:
 ```
  python3 create_data.py /data/classifier_data/intent_phrases.json -p
  python /data/classifier_data/train_model.py --data_path /data/classifier_data/intent_data.json --model_path /data/classifier_data/models/linear_classifier.h5
``
