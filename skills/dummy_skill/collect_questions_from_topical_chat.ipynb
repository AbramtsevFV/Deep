{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valid_rare.json',\n",
       " 'topical_chat_movies',\n",
       " 'topical_chat_cobot_annotated.tar.gz.md5',\n",
       " 'topical_chat_movies.tar.gz',\n",
       " 'topical_chat_sentiment_turn_rating.tar.gz.md5',\n",
       " 'topical_chat_movies.tar.gz.md5',\n",
       " 'annotated',\n",
       " 'valid_freq.json',\n",
       " 'topical_chat_sentiment_turn_rating',\n",
       " 'topical_chat_sentiment_turn_rating.tar.gz',\n",
       " 'test_rare.json',\n",
       " 'topical_chat_cobot_annotated',\n",
       " 'topical_chat_cobot_annotated.tar.gz',\n",
       " 'train.json',\n",
       " 'test_freq.json']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "fpath = \"/home/dilyara/Documents/GitHub/alexa-prize-topical-chat-dataset/conversations/\"\n",
    "os.listdir(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Politics', 'Movies_TV']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_KEY = \"MYF6T5vloa7UIfT1LwftY3I33JmzlTaA86lwlVGm\"\n",
    "\n",
    "import requests\n",
    "\n",
    "headers = {'Content-Type': 'application/json;charset=utf-8', 'x-api-key': API_KEY}\n",
    "SERVICE_URL = 'https://gpri4649wf.execute-api.us-east-1.amazonaws.com/prod/topic/v1/batchTopics'\n",
    "utterances=[\"let's chat about politics\", 'I love watching movies.']\n",
    "\n",
    "result = requests.request(url=SERVICE_URL, headers=headers, data=json.dumps({'utterances': utterances}), method='POST').json()\n",
    "\n",
    "[r[\"topicClass\"] for r in result[\"topics\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fpath + \"train.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "punctuation = '!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "for k in data.keys():\n",
    "    for message in data[k][\"content\"]:\n",
    "        sentences = sent_tokenize(message[\"message\"])\n",
    "        if len(sentences) == 1 and message[\"message\"][-1] == \"?\":\n",
    "            punct = re.findall(f\"[{punctuation}]\", message[\"message\"])\n",
    "            if punct != [\"?\"]:\n",
    "                punct = message[\"message\"].rfind(punct[-2])\n",
    "            else:\n",
    "                punct = -1\n",
    "            quest = message[\"message\"][punct+1:].strip()\n",
    "            quest = re.sub(f\"^hi(\\sthere)?[{punctuation}\\s]*\", \"\", quest.lower())\n",
    "            quest = re.sub(f\"^hey(\\sthere)?[{punctuation}\\s]*\", \"\", quest.lower())\n",
    "            quest = re.sub(f\"^hello(\\sthere)?[{punctuation}\\s]*\", \"\", quest.lower())\n",
    "            quest = re.sub(f\"^yes[{punctuation}\\s]*\", \"\", quest.lower())\n",
    "            quest = re.sub(f\"^yeah[{punctuation}\\s]*\", \"\", quest.lower())\n",
    "            quest = re.sub(f\"^sure[{punctuation}\\s]*\", \"\", quest.lower())\n",
    "            quest = re.sub(f\"^no[{punctuation}\\s]*\", \"\", quest.lower())\n",
    "            if \"how are you\" in quest.lower():\n",
    "                quest = \"\"\n",
    "            quest = re.sub(f\"\\t+\", \" \", quest.lower())\n",
    "            if len(quest.split()) > 3:\n",
    "                questions += [quest]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3566"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2113"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = list(set(questions))\n",
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "all_topics = []\n",
    "\n",
    "for i in range(int(len(questions) / batch_size) + 1):\n",
    "    utterances = questions[i * batch_size: (i+1)* batch_size]\n",
    "    try:\n",
    "        result = requests.request(url=SERVICE_URL, headers=headers, data=json.dumps({'utterances': utterances}), method='POST').json()\n",
    "    except:\n",
    "        print(utterances)\n",
    "        break\n",
    "    topics = [r[\"topicClass\"] for r in result[\"topics\"]]\n",
    "    all_topics.extend(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2113"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>did you know that dogs have 12 different blood...</td>\n",
       "      <td>Pets_Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>do you ever watch shows on netflix?</td>\n",
       "      <td>Movies_TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>did you know the drive thru was invented in 1975?</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>do you know what the highest scoring football ...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>do you like watching baseball?</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>do you like to laugh?</td>\n",
       "      <td>Phatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>do you like star trek?</td>\n",
       "      <td>Phatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>what do you think about lane lambert and the p...</td>\n",
       "      <td>Art_Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>do you watch basketball?</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>did you know the only fish to have a neck is t...</td>\n",
       "      <td>Pets_Animals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question         topic\n",
       "0    did you know that dogs have 12 different blood...  Pets_Animals\n",
       "1                  do you ever watch shows on netflix?     Movies_TV\n",
       "2    did you know the drive thru was invented in 1975?         Other\n",
       "3    do you know what the highest scoring football ...        Sports\n",
       "4                       do you like watching baseball?        Sports\n",
       "..                                                 ...           ...\n",
       "96                               do you like to laugh?        Phatic\n",
       "97                              do you like star trek?        Phatic\n",
       "98   what do you think about lane lambert and the p...     Art_Event\n",
       "99                            do you watch basketball?        Sports\n",
       "100  did you know the only fish to have a neck is t...  Pets_Animals\n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"question\": questions, \"topic\": all_topics})\n",
    "df.loc[:100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"questions_with_topics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>did you know that dogs have 12 different blood...</td>\n",
       "      <td>Pets_Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>do you ever watch shows on netflix?</td>\n",
       "      <td>Movies_TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>did you know the drive thru was invented in 1975?</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>do you know what the highest scoring football ...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>do you like watching baseball?</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question         topic\n",
       "0  did you know that dogs have 12 different blood...  Pets_Animals\n",
       "1                do you ever watch shows on netflix?     Movies_TV\n",
       "2  did you know the drive thru was invented in 1975?         Other\n",
       "3  do you know what the highest scoring football ...        Sports\n",
       "4                     do you like watching baseball?        Sports"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/dilyara/Documents/GitHub/dp-agent-alexa/skills/dummy_skill/questions_with_topics.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cobot Nounphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['her boobs', 'this room']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_URL = 'http://0.0.0.0:8016/nounphrases'\n",
    "\n",
    "dialog = {\"utterances\": [{\"text\": \"Her boobs are in this room tonight\"}]}\n",
    "\n",
    "result = requests.request(url=SERVICE_URL, json={'dialogs': [dialog]}, method='POST').json()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    df_dict.append({\"question\": df.loc[i, \"question\"], \"topic\": df.loc[i, \"topic\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "all_topics = []\n",
    "\n",
    "for i in range(int(len(df_dict) / batch_size) + 1):\n",
    "\n",
    "    dialogs = [deepcopy(dialog) for _ in df_dict[i * batch_size: (i+1)* batch_size]] \n",
    "\n",
    "    for dialog, el in zip(dialogs, df_dict[i * batch_size: (i+1)* batch_size]):\n",
    "        dialog[\"utterances\"][-1][\"text\"] = el[\"question\"]\n",
    "    try:\n",
    "        nounphrases = requests.request(url=SERVICE_URL, json={'dialogs': dialogs}, method='POST').json()\n",
    "    except:\n",
    "        print(dialogs)\n",
    "\n",
    "    for el, np in zip(df_dict[i * batch_size: (i+1)* batch_size], nounphrases):\n",
    "        el[\"nounphrases\"] = np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/topical_chat_questions_nouns.json\", \"w\") as f:\n",
    "    json.dump(df_dict, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear nounphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_ignore_list = [\"'s\", 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\",\n",
    "                  \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself',\n",
    "                  'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\n",
    "                  'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those',\n",
    "                  'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "                  'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of',\n",
    "                  'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before',\n",
    "                  'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n",
    "                  'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any',\n",
    "                  'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
    "                  'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should',\n",
    "                  \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',\n",
    "                  \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven',\n",
    "                  \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\",\n",
    "                  'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\",\n",
    "                  'wouldn', \"wouldn't\", \"my name\", \"your name\", \"wow\", \"yeah\", \"yes\", \"ya\", \"cool\", \"okay\", \"more\",\n",
    "                  \"some more\", \" a lot\", \"a bit\", \"another one\", \"something else\", \"something\", \"anything\",\n",
    "                  \"someone\", \"anyone\", \"play\", \"mean\", \"a lot\", \"a little\", \"a little bit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total non-unique nounphrases: 2601\n",
      "Total unique nounphrases: 1419\n"
     ]
    }
   ],
   "source": [
    "unique_nps = []\n",
    "\n",
    "for sample in df_dict:\n",
    "    for np in sample[\"nounphrases\"]:\n",
    "        for ignore_np in np_ignore_list:\n",
    "            np = re.sub(\"\\s\\s+\", \" \", re.sub(r\"\\b\" + ignore_np + r\"\\b\", \"\", np)).strip()\n",
    "        if len(np) >= 3:\n",
    "            unique_nps.append(np)\n",
    "print(f\"Total non-unique nounphrases: {len(unique_nps)}\")\n",
    "unique_nps = list(set(unique_nps))\n",
    "print(f\"Total unique nounphrases: {len(unique_nps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_to_fact_map = {}\n",
    "\n",
    "for key in unique_nps:\n",
    "    np_to_fact_map[key] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_info = {}\n",
    "\n",
    "total_id = 0\n",
    "\n",
    "for sample in df_dict:\n",
    "    question_info[total_id] = sample[\"question\"]\n",
    "    total_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_id in question_info.keys():\n",
    "    for np in np_to_fact_map.keys():\n",
    "        if np in question_info[sample_id]:\n",
    "            np_to_fact_map[np] += [sample_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_nps = []\n",
    "\n",
    "for key in np_to_fact_map:\n",
    "    if len(np_to_fact_map[key]) == 0:\n",
    "        bad_nps.append(key)\n",
    "        \n",
    "for np in bad_nps:\n",
    "    np_to_fact_map.pop(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1375"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_to_fact_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/questions_map.json\", \"w\") as f:\n",
    "    json.dump(question_info, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/nounphrases_questions_map.json\", \"w\") as f:\n",
    "    json.dump(np_to_fact_map, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py36Agent",
   "language": "python",
   "name": "py36_agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
