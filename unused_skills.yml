services:
  aiml:
    build:
      args:
        skill_endpoint: aiml
        skillconfig: skills/aiml/aiml_skill.json
        skillhost: 0.0.0.0
        skillport: 2080
      context: ./
      dockerfile: dp/dockerfile_skill_cpu
    environment:
      - CUDA_VISIBLE_DEVICES=""
    ports:
      - 2080:2080
  transfertransfo:
    build:
      context: ./skills/transfertransfo/
    environment:
      DEVICE: cuda
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8007 -t 60
    volumes: []
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.with_gpu == true
  retrieval_chitchat:
    build:
      context: ./skills/retrieval_chitchat/
    command: uvicorn server:app --host 0.0.0.0 --port 8015
    volumes: []
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.with_gpu != true
  convert_reddit_with_personality:
    build:
      context: ./skills/convert_reddit_with_personality/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8048 -t 60
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  news_skill:
    build:
      context: .
      dockerfile: ./skills/alexa-prize-news/Dockerfile
    command: bash -c "python updater.py | gunicorn --workers=1 server:app -b 0.0.0.0:8027 -t 300"
    volumes: []
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.with_gpu != true
  topicalchat_convert_retrieval:
    build:
      context: ./skills/topicalchat_convert_retrieval/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8060 -t 60
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
          - node.labels.group == 0
version: '3.7'
