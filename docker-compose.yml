services:
  agent:
    command: sh -c './utils/setup_cron.sh && bin/wait && python3 run.py -ch http_client -rl -d -pl alexa_pipeline_conf.json -db db_conf.json'
    build:
      context: ./
      dockerfile: dockerfile_agent
    ports:
      - 4242:4242
    environment:
      WAIT_HOSTS: "rule_based_selector:8002, cobotqa:8001, cobot_topics:8003, cobot_offensiveness:8005,
        cobot_dialogact:8006, program_y:8008, sentseg:8011, convers_evaluation_selector:8009, personality_catcher:8010,
        intent_responder:8012, intent_catcher:8014, cobot_nounphrases:8016, blacklisted_words:8018, dummy_skill:8019,
        toxic_classification:8013, sentrewrite:8017, ner:8021,  program_y_dangerous:8022, movie_skill:8023,  
        sentiment_classification:8024, attitude_classification:8025, news_skill:8027, tfidf_retrieval:8028, 
        convert_reddit:8029, personal_info_skill:8030, asr:8031, book_skill:8032, misheard_asr:8033, 
        christmas_new_year_skill:8036, weather_skill:8037, alice:8000, eliza:8047"
      WAIT_HOSTS_TIMEOUT: 480
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.with_gpu != true
  rule_based_selector:
    build:
      context: .
      dockerfile: ./skill_selectors/rule_based_selector/Dockerfile
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8002
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  cobotqa:
    build:
      context: ./skills/CoBotQA/
    environment:
      - ASYNC_SIZE=20
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8001 -t 15
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  cobot_topics:
    build:
      context: ./annotators/CoBotTopicClassification/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8003 -t 15
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  cobot_offensiveness:
    build:
      context: ./annotators/CoBotOffensiveSpeechClassification/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8005 -t 15
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  cobot_dialogact:
    build:
      context: ./annotators/CoBotDialogActClassification/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8006 -t 15
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  program_y:
    build:
      context: ./skills/program-y/
    working_dir: /src/dream_aiml/scripts/xnix
    command: ./sanic.sh
    healthcheck:
      test: ["CMD-SHELL", "curl -s --header \"Content-Type: application/json\" --request POST --data '{\"sentences_batch\":[[\"lets chat\"]],\"user_ids\":[123131]}' http://localhost:8008/api/rest/v1.0/ask || exit 1"]
      interval: 10s
      timeout: 2s
      retries: 3
      start_period: 1m
    deploy:
      mode: replicated
      replicas: 4
      placement:
        constraints:
          - node.labels.with_gpu != true
      resources:
        limits:
          memory: 2G
  personality_catcher:
    build:
      context: ./skills/personality_catcher/
    command: uvicorn server:app --host 0.0.0.0 --port 8010
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  sentseg:
    build:
      context: ./annotators/SentSeg/
    command: bash -c "./setup.sh && gunicorn --workers=1 server:app -b 0.0.0.0:8011 -t 100"
    volumes: []
    deploy:
      mode: replicated
      replicas: 4
      placement:
        constraints:
          - node.labels.with_gpu != true
  convers_evaluation_selector:
    build:
      context: ./response_selectors/convers_evaluation_based_selector/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8009 -t 15
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  toxic_classification:
    build:
      args:
        skill_endpoint: toxicity_annotations
        skillconfig: annotators/DeepPavlovToxicClassification/toxic_classification.json
        skillhost: 0.0.0.0
        skillport: 8013
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.with_gpu == true
  sentiment_classification:
    build:
      args:
        skill_endpoint: sentiment_annotations
        skillconfig: annotators/DeepPavlovSentimentClassification/sentiment_yelp_conv_bert.json
        skillhost: 0.0.0.0
        skillport: 8024
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.with_gpu == true
  sentrewrite:
    build:
      context: ./annotators/SentRewrite/
    command: bash -c "./setup.sh && gunicorn --workers=1 server:app -b 0.0.0.0:8017 -t 60"
    deploy:
      mode: replicated
      replicas: 4
      placement:
        constraints:
          - node.labels.with_gpu != true
  intent_responder:
    build:
      context: ./skills/IntentResponder/
    command: gunicorn --workers=1 --name=responder --bind 0.0.0.0:8012 --timeout=100 server:app
    volumes: []
    deploy:
      mode: replicated
      replicas: 4
      placement:
        constraints:
          - node.labels.with_gpu != true
  intent_catcher:
    build:
      context: ./annotators/IntentCatcher/
    command: gunicorn --workers=1 --name=catcher --bind 0.0.0.0:8014 --timeout=100 server:app
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
      resources:
        limits:
          memory: 6G
  blacklisted_words:
    build:
      context: ./annotators/BlacklistedWordsDetector/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8018
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  dummy_skill:
    build:
      context: ./skills/dummy_skill/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8019
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  program_y_dangerous:
    build:
      context: ./skills/program-y-dangerous/
    working_dir: /src/dream_aiml/scripts/xnix
    command: ./sanic.sh
    healthcheck:
      test: ["CMD-SHELL", "curl -s --header \"Content-Type: application/json\" --request POST --data '{\"sentences_batch\":[[\"i want to commit a suicide\"]],\"user_ids\":[123131]}' http://localhost:8022/api/rest/v1.0/ask || exit 1"]
      interval: 10s
      timeout: 2s
      retries: 3
      start_period: 1m
    deploy:
      mode: replicated
      replicas: 4
      placement:
        constraints:
          - node.labels.with_gpu != true
      resources:
        limits:
          memory: 2G
  cobot_nounphrases:
    build:
      context: ./annotators/nounphrases/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8016
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  movie_skill:
    build:
      context: ./skills/movie_skill/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8023 --timeout=300
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
      resources:
        limits:
          memory: 6G
  ner:
    build:
      context: ./annotators/NER/
    environment:
      DEVICE: cuda
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8021 -t 100
    volumes: []
    tty: true
    deploy:
      mode: replicated
      replicas: 4
      placement:
        constraints:
          - node.labels.with_gpu != true
  attitude_classification:
    build:
      args:
        skill_endpoint: attitude_annotations
        skillconfig: annotators/DeepPavlovAttitudeClassification/amazon_reviews_bert.json
        skillhost: 0.0.0.0
        skillport: 8025
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.labels.with_gpu == true
  alice:
    build:
      context: ./skills/ALICEChatAPI/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8000
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  eliza:
    build:
      context: ./skills/eliza/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8047
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  tfidf_retrieval:
    build:
      context: ./skills/tfidf_retrieval/
    command: bash -c " gunicorn --workers=1 server:app -b 0.0.0.0:8028"
    volumes: []
    deploy:
      mode: replicated
      replicas: 4
      placement:
        constraints:
          - node.labels.with_gpu != true
  book_tfidf_retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_book_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: book
        CONFIDENCE_THRESHOLD: 0.51
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8039
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  entertainment_tfidf_retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_entertainment_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: entertainment
        CONFIDENCE_THRESHOLD: 0.59
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8040
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  fashion_tfidf_retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_fashion_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: fashion
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8041
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  movie_tfidf_retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_movie_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: movie
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8042
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  music_tfidf_retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_music_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: music
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8034
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  politics_tfidf_retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_politics_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: politics
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8043
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  science_technology_tfidf_retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_science_technology_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: science_technology
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8044
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  sport_tfidf_retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_sport_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: sport
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8045
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  animals_tfidf_retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_animals_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: animals
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8050
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  convert_reddit:
    build:
      context: ./skills/convert_reddit/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8029 -t 60
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  personal_info_skill:
    build:
      context: .
      dockerfile: ./skills/personal_info_skill/Dockerfile
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8030
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  asr:
    build:
      context: ./annotators/asr/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8031
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  misheard_asr:
    build:
      context: ./skills/misheard_asr/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8033
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  book_skill:
    build:
      context: ./skills/book_skill/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8032
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  christmas_new_year_skill:
    build:
      context: ./skills/christmas_new_year_skill/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8036
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  weather_skill:
    build:
      context: ./skills/weather_skill/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8037
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
  news_skill:
    build:
      context: .
      dockerfile: ./skills/alexa-prize-news/Dockerfile
    command: bash -c "python updater.py | gunicorn --workers=2 server:app -b 0.0.0.0:8027 -t 300"
    volumes: []
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints:
          - node.labels.with_gpu != true
version: '3.7'
