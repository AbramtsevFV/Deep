services:
  agent:
    command: sh -c 'bin/wait && python -m deeppavlov_agent.run -ch http_client --cors'
    build:
      context: ./
      dockerfile: dockerfile_agent
    environment:
      WAIT_HOSTS: "cobotqa:8081, cobot-convers-evaluator-annotator:8004,
        cobot-nounphrases:8006, program-y:8008, sentseg:8011, convers-evaluation-selector:8009, personality-catcher:8010,
        intent-responder:8012, intent-catcher:8014, blacklisted-words:8018,
         sentrewrite:8017, ner:8021,  program-y-dangerous:8022, movie-skill:8023,
        convert-reddit:8029, personal-info-skill:8030, asr:8031, misheard-asr:8033,
        christmas-new-year-skill:8036, weather-skill:8037,  alice:8000,
        eliza:8047, emotion-skill:8049, dummy-skill-dialog:8052, comet-atomic:8053, meta-script-skill:8054,
        oscar-skill:8055, coronavirus-skill:8061, small-talk-skill:8062, game-cooperative-skill:8068, program-y-wide:8064,
        comet-conceptnet:8065, news-api-skill:8066, short-story-skill:8057, greeting-skill:8070, factoid-qa:8071, kbqa:8072,
        factoid-classification:8073, spelling-preprocessing:8074, entity-linking:8075, wiki-parser:8077, odqa:8078,
        knowledge-grounding:8083, combined-classification:8087, dialog-breakdown:8082, knowledge-grounding-skill:8085,
        wikidata-dial-skill:8091"
      WAIT_HOSTS_TIMEOUT: ${WAIT_TIMEOUT:-480}
    deploy:
      mode: replicated
      replicas: 8
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  cobotqa:
    build:
      context: .
      dockerfile: ./skills/CoBotQA/Dockerfile
    environment:
      - ASYNC_SIZE=20
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8081 -t 15
    deploy:
      mode: replicated
      replicas: 8
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M


  cobot-topics:
    build:
      context: ./annotators/CoBotTopicClassification/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8000 -t 15
    deploy:
      mode: replicated
      replicas: 8
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  cobot-dialogact:
    build:
      context: ./annotators/CoBotDialogActClassification/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8002 -t 15
    deploy:
      mode: replicated
      replicas: 8
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  cobot-convers-evaluator-annotator:
    build:
      context: ./annotators/CoBotConversationEvaluator/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8004 -t 15
    deploy:
      mode: replicated
      replicas: 8
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  cobot-nounphrases:
    build:
      context: ./annotators/cobot_nounphrases/
    command: bash -c "gunicorn --workers=1 server:app -b 0.0.0.0:8006 -t 60"
    deploy:
      mode: replicated
      replicas: 8
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  program-y:
    build:
      context: .
      dockerfile: ./skills/program-y/Dockerfile
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 768M
        reservations:
          memory: 768M

  personality-catcher:
    build:
      context: ./skills/personality_catcher/
    command: uvicorn server:app --host 0.0.0.0 --port 8010
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  sentseg:
    build:
      context: ./annotators/SentSeg/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8011 -t 100
    deploy:
      mode: replicated
      replicas: 8
      resources:
        limits:
          memory: 1.5G
        reservations:
          memory: 1.5G

  convers-evaluation-selector:
    build:
      context: .
      dockerfile: ./response_selectors/convers_evaluation_based_selector/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8009 -t 15
    deploy:
      mode: replicated
      replicas: 8
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  sentrewrite:
    build:
      context: ./annotators/SentRewrite/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8017 -t 60
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 512M

  intent-responder:
    build:
      context: .
      dockerfile: ./skills/IntentResponder/Dockerfile
    command: gunicorn --workers=1 --name=responder --bind 0.0.0.0:8012 --timeout=100 server:app
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  intent-catcher:
    build:
      context: ./annotators/IntentCatcher/
    command: gunicorn --workers=1 --name=catcher --bind 0.0.0.0:8014 --timeout=100 server:app
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 3G

  blacklisted-words:
    build:
      context: ./annotators/BlacklistedWordsDetector/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8018
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  program-y-dangerous:
    build:
      context: ./skills/program-y-dangerous/
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  movie-skill:
    build:
      context: .
      dockerfile: ./skills/movie_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8023 --timeout=300 --preload
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 768M
        reservations:
          memory: 768M

  ner:
    build:
      context: ./annotators/NER/
    environment:
      DEVICE: cuda
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8021 -t 100
    tty: true
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 1512M
        reservations:
          memory: 1512M

  alice:
    build:
      context: ./skills/ALICEChatAPI/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8000
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 512M

  eliza:
    build:
      context: ./skills/eliza/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8047
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  book-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_book_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: book
        CONFIDENCE_THRESHOLD: 0.51
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8039
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 170M
        reservations:
          memory: 170M

  entertainment-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_entertainment_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: entertainment
        CONFIDENCE_THRESHOLD: 0.59
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8040
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 170M
        reservations:
          memory: 170M

  fashion-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_fashion_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: fashion
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8041
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 170M
        reservations:
          memory: 170M

  movie-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_movie_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: movie
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8042
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 170M
        reservations:
          memory: 170M

  music-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_music_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: music
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8034
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 170M
        reservations:
          memory: 170M

  politics-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_politics_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: politics
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8043
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 170M
        reservations:
          memory: 170M

  science-technology-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_science_technology_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: science_technology
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8044
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 170M
        reservations:
          memory: 170M

  sport-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_sport_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: sport
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8045
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 170M
        reservations:
          memory: 170M

  animals-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_animals_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: animals
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8050
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 170M
        reservations:
          memory: 170M

  convert-reddit:
    build:
      context: ./skills/convert_reddit/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8029 -t 60
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 1536M
        reservations:
          memory: 1536M

  personal-info-skill:
    build:
      context: .
      dockerfile: ./skills/personal_info_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8030
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  asr:
    build:
      context: .
      dockerfile: ./annotators/asr/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8031
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  misheard-asr:
    build:
      context: ./skills/misheard_asr/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8033
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 196M
        reservations:
          memory: 196M

  book-skill:
    build:
      context: .
      dockerfile: ./skills/book_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8032
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  christmas-new-year-skill:
    build:
      context: ./skills/christmas_new_year_skill/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8036
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  superbowl-skill:
    build:
      context: ./skills/superbowl_skill/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8051
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  oscar-skill:
    build:
      context: ./skills/oscar_skill/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8055
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  valentines-day-skill:
    build:
      context: ./skills/valentines_day_skill/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8058
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  weather-skill:
    build:
            context: .
            dockerfile: ./skills/weather_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8037
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 1152M
        reservations:
          memory: 1152M

  emotion-skill:
    build:
      context: .
      dockerfile: ./skills/emotion_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8049
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  dummy-skill-dialog:
    build:
      context: ./skills/dummy_skill_dialog/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8052
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 768M
        reservations:
          memory: 768M

  comet-atomic:
    build:
      context: ./annotators/COMeT/
      args:
        GRAPH: atomic
        PRETRAINED_MODEL: http://lnsigo.mipt.ru/export/alexaprize_data/comet/atomic_pretrained_model.pickle
        PREPROCESS_DATA: "http://lnsigo.mipt.ru/export/alexaprize_data/comet/categories_oEffect%23oReact%23oWant%23xAttr%23xEffect%23xIntent%23xNeed%23xReact%23xWant-maxe1_17-maxe2_35-maxr_1.pickle"
        TEST_SCRIPT: test_atomic.py
        DECODING_ALGO: beam-3
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8053
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - DEVICE=gpu_0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  comet-conceptnet:
    build:
      context: ./annotators/COMeT/
      args:
        GRAPH: conceptnet
        PRETRAINED_MODEL: http://lnsigo.mipt.ru/export/alexaprize_data/conceptnet/conceptnet_pretrained_model.pickle
        PREPROCESS_DATA: http://lnsigo.mipt.ru/export/alexaprize_data/conceptnet/rel_language-trainsize_100-devversion_12-maxe1_10-maxe2_15-maxr_5.pickle
        DECODING_ALGO: beam-3
        TEST_SCRIPT: test_conceptnet.py
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8065
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - DEVICE=gpu_0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        reservations:
          memory: 2G
        limits:
          memory: 2G

  meta-script-skill:
    build:
      context: .
      dockerfile: skills/meta_script_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8054
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  short-story-skill:
    build:
      context: .
      dockerfile: ./skills/short_story_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8057
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  coronavirus-skill:
    build:
      context: .
      dockerfile: ./skills/coronavirus_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8061
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  small-talk-skill:
    build:
      context: .
      dockerfile: ./skills/small_talk_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8062
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  game-cooperative-skill:
    build:
      args:
        SERVICE_PORT: 8068
      context: .
      dockerfile: ./skills/game_cooperative_skill/Dockerfile
    command: bash server_run.sh "gunicorn --workers=1 server:app -b 0.0.0.0:8068 --reload"
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  program-y-wide:
    build:
      context: ./skills/program-y-wide/
    command: sh -c "./sanic.sh"
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  news-api-skill:
    build:
      context: .
      dockerfile: ./skills/news_api_skill/Dockerfile
    environment:
      - ASYNC_SIZE=3
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8066 -t 15
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  greeting-skill:
    build:
      context: .
      dockerfile: ./skills/greeting_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8070 --timeout=60 --preload
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  factoid-qa:
    build:
      context: .
      dockerfile: ./skills/factoid_qa/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8071
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  entity-linking:
    build:
      args:
        CONFIG: kbqa_entity_linking_lite.json
        PORT: 8075
        SRC_DIR: annotators/entity_linking
        COMMIT: ff3ac8ca31006196388d934cfcbd7a82b2483333
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=''
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 20G
        reservations:
          memory: 20G

  wiki-parser:
    build:
      args:
        CONFIG: wiki_parser.json
        PORT: 8077
        SRC_DIR: annotators/wiki_parser
        COMMIT: 2680ef300a1941c183f4cd91eb24ceba0706fce3
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=''
    deploy:
      mode: replicated
      replicas: 8
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  odqa:
    build:
      args:
        CONFIG: en_odqa_infer_wiki_tch.json
        PORT: 8078
        SRC_DIR: annotators/odqa/
        COMMIT: 1ad1d7b3831b0276368a43fc59a1dab1f898104f
      context: ./
      dockerfile: annotators/odqa/Dockerfile_odqa_lite
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 15G
        reservations:
          memory: 15G

  kbqa:
    build:
      args:
        CONFIG: kbqa_cq_mt_bert_lite.json
        PORT: 8072
        SRC_DIR: annotators/kbqa/
        COMMIT: c3676867684ca42e71e7af935c8ec721104cd291
      context: ./
      dockerfile: annotators/kbqa/Dockerfile
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 20G
        reservations:
          memory: 20G

  factoid-classification:
    build:
      args:
        CONFIG: factoid_classification.json
        PORT: 8073
        SRC_DIR: annotators/DeepPavlovFactoidClassification
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  spelling-preprocessing:
    build:
      context: ./annotators/spelling_preprocessing/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8074 --timeout=100
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 512M

  grounding-skill:
    build:
      context: .
      dockerfile: ./skills/grounding_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8080 --timeout=60 --preload
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 512M

  question-generator:
    build:
      context: ./services/question_generator/
      args:
        MODEL_URL: http://lnsigo.mipt.ru/export/alexaprize_data/question_generator/model_24_0.94_37.23.pth
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8079
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - DECODING=greedy
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  knowledge-grounding:
    build:
      context: ./services/knowledge_grounding/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8083
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  dialog-breakdown:
    build:
      args:
        CONFIG: breakdown_config.json
        SRC_DIR: annotators/dialog_breakdown
        PORT: 8082
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 3.5G
        reservations:
          memory: 3.5G

  friendship-skill:
    build:
      args:
        SERVICE_PORT: 8086
      context: .
      dockerfile: ./skills/friendship_skill/Dockerfile
    command:  gunicorn --workers=1 server:app -b 0.0.0.0:8086 --reload
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 384M
        reservations:
          memory: 384M

  masked-lm:
    build:
      context: ./services/masked_lm/
      args:
        SERVICE_PORT: 8088
        PRETRAINED_MODEL_NAME_OR_PATH: "bert-base-uncased"
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8088
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  entity-storer:
    build:
      context: .
      dockerfile: annotators/entity_storer/Dockerfile
      args:
        WORK_DIR: annotators/entity_storer
        SERVICE_PORT: 8089
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8089 --reload
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 384M
        reservations:
          memory: 384M

  knowledge-grounding-skill:
    build:
      context: .
      dockerfile: ./skills/knowledge_grounding_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8085
    environment:
      - CUDA_VISIBLE_DEVICES=''
    deploy:
      mode: replicated
      replicas: 4
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  combined-classification:
    build:
      args:
        CONFIG: combined_classifier.json
        PORT: 8087
      context: .
      dockerfile: ./annotators/combined_classification/Dockerfile
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  wikidata-dial-skill:
    build:
      args:
        CONFIG: kg_dial_generator.json
        PORT: 8091
        COMMIT: 5dac85a06fde0e2983c7569ae058e3bf2d45ce2c
      context: skills/wikidata_dial_skill
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 10G
        reservations:
          memory: 10G

version: '3.7'
