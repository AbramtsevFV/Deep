services:
  agent:
    command: sh -c 'bin/wait && python -m deeppavlov_agent.run -ch http_client --cors'
    build:
      context: ./
      dockerfile: dockerfile_agent
    environment:
      WAIT_HOSTS: "cobot-topics:8001, cobot-dialogact-topics:8002, cobot-dialogact-intents:8003,
        cobot-nounphrases:8006, program-y:8008, sentseg:8011, convers-evaluation-selector:8009, personality-catcher:8010,
        intent-responder:8012, intent-catcher:8014, blacklisted-words:8018,
        toxic-classification:8013, sentrewrite:8017, ner:8021,  program-y-dangerous:8022, movie-skill:8023,
        sentiment-classification:8024,
        convert-reddit:8029, personal-info-skill:8030, asr:8031, misheard-asr:8033,
        christmas-new-year-skill:8036, weather-skill:8037, emotion-classification:8038, alice:8000,
        eliza:8047, emotion-skill:8049, dummy-skill-dialog:8052, comet-atomic:8053, meta-script-skill:8054,
        oscar-skill:8055, coronavirus-skill:8061, small-talk-skill:8062, game-cooperative-skill:8068, program-y-wide:8064,
        comet-conceptnet:8065, news-api-skill:8066, short-story-skill:8057, greeting-skill:8070, factoid-qa:8071, kbqa:8072,
        factoid-classification:8073, spelling-preprocessing:8074, entity-linking:8075, wiki-parser:8077, odqa:8078"
      WAIT_HOSTS_TIMEOUT: ${WAIT_TIMEOUT:-480}

  cobotqa:
    build:
      context: .
      dockerfile: ./skills/CoBotQA/Dockerfile
    environment:
      - ASYNC_SIZE=20
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8081 -t 15

  cobot-topics:
    build:
      args:
        CONFIG: cobot_bert.json
        SRC_DIR: annotators/cobot_topics
        PORT: 8001
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0

  cobot-dialogact-topics:
    build:
      args:
        CONFIG: cobot_bert.json
        PORT: 8002
        SRC_DIR: annotators/cobot_dialogact_topics
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0

  cobot-dialogact-intents:
    build:
      args:
        CONFIG: cobot_bert.json
        PORT: 8003
        SRC_DIR: annotators/cobot_dialogact_intents
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0

  cobot-convers-evaluator-annotator:
    build:
      args:
        CONFIG: cobot_conveval_bert.json
        PORT: 8004
        SRC_DIR: annotators/cobot_convers_evaluator_annotator
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0

  cobot-nounphrases:
    build:
      context: ./annotators/cobot_nounphrases/
    command: bash -c "gunicorn --workers=1 server:app -b 0.0.0.0:8006 -t 60"
  program-y:
    build:
      context: .
      dockerfile: ./skills/program-y/Dockerfile

  personality-catcher:
    build:
      context: ./skills/personality_catcher/
    command: uvicorn server:app --host 0.0.0.0 --port 8010

  sentseg:
    build:
      context: ./annotators/SentSeg/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8011 -t 100

  convers-evaluation-selector:
    build:
      context: .
      dockerfile: ./response_selectors/convers_evaluation_based_selector/Dockerfile
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8009 -t 15

  toxic-classification:
    build:
      args:
        CONFIG: toxic_classification.json
        PORT: 8013
        SRC_DIR: annotators/DeepPavlovToxicClassification
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0

  sentiment-classification:
    build:
      args:
        CONFIG: sentiment_sst_conv_bert.json
        PORT: 8024
        SRC_DIR: annotators/DeepPavlovSentimentClassification
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0

  sentrewrite:
    build:
      context: ./annotators/SentRewrite/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8017 -t 60

  intent-responder:
    build:
      context: ./skills/IntentResponder/
    command: gunicorn --workers=1 --name=responder --bind 0.0.0.0:8012 --timeout=100 server:app

  intent-catcher:
    build:
      context: ./annotators/IntentCatcher/
    command: gunicorn --workers=1 --name=catcher --bind 0.0.0.0:8014 --timeout=100 server:app

  blacklisted-words:
    build:
      context: ./annotators/BlacklistedWordsDetector/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8018

  program-y-dangerous:
    build:
      context: ./skills/program-y-dangerous/

  movie-skill:
    build:
      context: .
      dockerfile: ./skills/movie_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8023 --timeout=300 --preload

  ner:
    build:
      context: ./annotators/NER/
    environment:
      DEVICE: cuda
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8021 -t 100
    tty: true

  alice:
    build:
      context: ./skills/ALICEChatAPI/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8000

  eliza:
    build:
      context: ./skills/eliza/
    command: gunicorn --workers=2 server:app -b 0.0.0.0:8047

  book-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_book_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: book
        CONFIDENCE_THRESHOLD: 0.51
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8039

  entertainment-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_entertainment_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: entertainment
        CONFIDENCE_THRESHOLD: 0.59
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8040

  fashion-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_fashion_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: fashion
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8041

  movie-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_movie_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: movie
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8042

  music-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_music_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: music
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8034

  politics-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_politics_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: politics
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8043

  science-technology-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_science_technology_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: science_technology
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8044

  sport-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_sport_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: sport
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8045

  animals-tfidf-retrieval:
    build:
      context: ./skills/topicalchat_tfidf_retrieval/
      args:
        TOPICAL_DATA_URL: http://lnsigo.mipt.ru/export/alexaprize_data/topicalchat_tfidf_retrieval/topicalchat_animals_data.tar.gz
        MODELS_URL: http://lnsigo.mipt.ru/export/models/new_vectorizer_2.zip
        TOPIC_NAME: animals
        CONFIDENCE_THRESHOLD: 0.6
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8050

  convert-reddit:
    build:
      context: ./skills/convert_reddit/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8029 -t 60

  personal-info-skill:
    build:
      context: .
      dockerfile: ./skills/personal_info_skill/Dockerfile
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8030

  asr:
    build:
      context: .
      dockerfile: ./annotators/asr/Dockerfile
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8031

  misheard-asr:
    build:
      context: ./skills/misheard_asr/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8033

  book-skill:
    build:
      context: .
      dockerfile: ./skills/book_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8032

  christmas-new-year-skill:
    build:
      context: ./skills/christmas_new_year_skill/
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8036

  superbowl-skill:
    build:
      context: ./skills/superbowl_skill/
    command: gunicorn --workers=2 server:app -b 0.0.0.0:8051

  oscar-skill:
    build:
      context: ./skills/oscar_skill/
    command: gunicorn --workers=2 server:app -b 0.0.0.0:8055

  valentines-day-skill:
    build:
      context: ./skills/valentines_day_skill/
    command: gunicorn --workers=2 server:app -b 0.0.0.0:8058

  weather-skill:
    build:
            context: .
            dockerfile: ./skills/weather_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8037

  emotion-skill:
    build:
      context: .
      dockerfile: ./skills/emotion_skill/Dockerfile
    command: gunicorn --workers=2 server:app -b 0.0.0.0:8049

  emotion-classification:
    build:
      args:
        CONFIG: emo_bert.json
        PORT: 8038
        SRC_DIR: annotators/DeepPavlovEmotionClassification
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0

  dummy-skill-dialog:
    build:
      context: ./skills/dummy_skill_dialog/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8052

  comet-atomic:
    build:
      context: ./annotators/COMeT/
      args:
        GRAPH: atomic
        PRETRAINED_MODEL: http://lnsigo.mipt.ru/export/alexaprize_data/comet/atomic_pretrained_model.pickle
        PREPROCESS_DATA: "http://lnsigo.mipt.ru/export/alexaprize_data/comet/categories_oEffect%23oReact%23oWant%23xAttr%23xEffect%23xIntent%23xNeed%23xReact%23xWant-maxe1_17-maxe2_35-maxr_1.pickle"
        TEST_SCRIPT: test_atomic.py
        DECODING_ALGO: beam-3
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8053
    environment:
      - CUDA_VISIBLE_DEVICES=0

  comet-conceptnet:
    build:
      context: ./annotators/COMeT/
      args:
        GRAPH: conceptnet
        PRETRAINED_MODEL: http://lnsigo.mipt.ru/export/alexaprize_data/conceptnet/conceptnet_pretrained_model.pickle
        PREPROCESS_DATA: http://lnsigo.mipt.ru/export/alexaprize_data/conceptnet/rel_language-trainsize_100-devversion_12-maxe1_10-maxe2_15-maxr_5.pickle
        DECODING_ALGO: beam-3
        TEST_SCRIPT: test_conceptnet.py
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8065
    environment:
      - CUDA_VISIBLE_DEVICES=0

  meta-script-skill:
    build:
      context: .
      dockerfile: skills/meta_script_skill/Dockerfile
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8054

  short-story-skill:
    build:
      context: .
      dockerfile: ./skills/short_story_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8057

  stop-detect:
    build:
      args:
        CONFIG: stop_detect.json
        PORT: 8056
        SRC_DIR: annotators/stop_detect
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0

  coronavirus-skill:
    build:
      context: .
      dockerfile: ./skills/coronavirus_skill/Dockerfile
    command: gunicorn --workers=4 server:app -b 0.0.0.0:8061

  small-talk-skill:
    build:
      context: .
      dockerfile: ./skills/small_talk_skill/Dockerfile
    command: gunicorn --workers=2 server:app -b 0.0.0.0:8062

  game-cooperative-skill:
    build:
      args:
        SERVICE_PORT: 8068
      context: .
      dockerfile: ./skills/game_cooperative_skill/Dockerfile
    command: bash server_run.sh "gunicorn --workers=2 server:app -b 0.0.0.0:8068 --reload"

  program-y-wide:
    build:
      context: ./skills/program-y-wide/
    command: ./sanic.sh

  news-api-skill:
    build:
      context: .
      dockerfile: ./skills/news_api_skill/Dockerfile
    environment:
      - ASYNC_SIZE=3
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8066 -t 15

  greeting-skill:
    build:
      context: .
      dockerfile: ./skills/greeting_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8070 --timeout=60 --preload

  factoid-qa:
    build:
      context: .
      dockerfile: ./skills/factoid_qa/Dockerfile
    command: gunicorn --workers=2 server:app -b 0.0.0.0:8071

  entity-linking:
    build:
      args:
        CONFIG: kbqa_entity_linking.json
        PORT: 8075
        SRC_DIR: annotators/entity_linking
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=''

  wiki-parser:
    build:
      args:
        CONFIG: wiki_parser.json
        PORT: 8077
        SRC_DIR: annotators/wiki_parser
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=''

  odqa:
    build:
      args:
        CONFIG: en_odqa_infer_wiki.json
        PORT: 8078
        SRC_DIR: annotators/odqa/
        COMMIT: 7b6b0dcd9499d209b222e059963eb4e4b1e83d1b
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0

  kbqa:
    build:
      args:
        CONFIG: kbqa_cq.json
        PORT: 8072
        SRC_DIR: annotators/kbqa/
        COMMIT: 46e0d9163667116176dbb622c0c48d6b4366fb7a
      context: ./
      dockerfile: annotators/kbqa/Dockerfile
    environment:
      - CUDA_VISIBLE_DEVICES=0

  factoid-classification:
    build:
      args:
        CONFIG: factoid_classification.json
        PORT: 8073
        SRC_DIR: annotators/DeepPavlovFactoidClassification
      context: ./
      dockerfile: dp/dockerfile_skill_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=0

  spelling-preprocessing:
    build:
      context: ./annotators/spelling_preprocessing/
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8074 --timeout=100

version: '3.7'
